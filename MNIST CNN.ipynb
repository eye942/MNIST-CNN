{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this workshop you will be building a Convolutional neural network to classify cats vs dogs. You will need to be familiar with the theory of CNNs. Visit our lesson [here](http://caisplusplus.usc.edu/blog/curriculum/lesson7) for more info. Only fill in the TODO sections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import sklearn.utils\n",
    "import random\n",
    "import pickle # used to save and restore python objects\n",
    "import gzip\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# We are setting this to be 5 epochs for fast training times. In practice we would have many more epochs. \n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "Load the train and test data sets. Do not modify this code at all. Make sure that your data for cats and dogs images is in ``./data``. You can find that data at https://www.kaggle.com/c/dogs-vs-cats/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the mnist data set\n",
    "# Taken from the mnist cais++ lesson\n",
    "f = gzip.open('mnist.pkl.gz', 'rb')\n",
    "train_set, valid_set, test_set = pickle.load(f, encoding = 'latin1')\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set has dimensionality (50000, 784)\n",
      "Test set has dimensionality (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Lets get started by loading the data.\n",
    "# Make sure you have the data downloaded to ./data\n",
    "# To download the data go to https://www.kaggle.com/c/dogs-vs-cats/data and download train.zip\n",
    "\n",
    "\n",
    "\n",
    "test_X,test_Y = test_set\n",
    "\n",
    "train_X,train_Y = train_set\n",
    "\n",
    "print('Train set has dimensionality %s' % str(train_X.shape))\n",
    "print('Test set has dimensionality %s' % str(test_X.shape))\n",
    "\n",
    "\n",
    "\n",
    "# Apply some normalization here.\n",
    "train_X = train_X.astype('float32')\n",
    "test_X = test_X.astype('float32')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "While not necessary for this problem you can go ahead and try some preprocessing steps to try to get higher accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######################################\n",
    "#TODO: (Optional)\n",
    "# Perform any data preprocessing steps\n",
    "\n",
    "\n",
    "\n",
    "######################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the network\n",
    "Here are some useful resources to help with defining a powerful network.\n",
    "- Convolution layers (use the 2D convolution) https://keras.io/layers/convolutional/\n",
    "- Batch norm layer https://keras.io/layers/normalization/\n",
    "- Layer initializers https://keras.io/initializers/\n",
    "- Dense layer https://keras.io/layers/core/#dense\n",
    "- Activation functions https://keras.io/layers/core/#activation\n",
    "- Regulizers: \n",
    "    - https://keras.io/layers/core/#dropout\n",
    "    - https://keras.io/regularizers/\n",
    "    - https://keras.io/callbacks/#earlystopping\n",
    "    - https://keras.io/constraints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "######################################\n",
    "#TODO:\n",
    "# Import necessary layers.\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Activation, MaxPooling2D, Dropout, Flatten, BatchNormalization,Reshape\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "\n",
    "######################################\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "######################################\n",
    "#TODO:\n",
    "# Define the network\n",
    "model.add(Reshape((28,28,1),input_shape=(784,)))\n",
    "model.add(Conv2D(16,(3,3)))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(120))\n",
    "model.add(Dense(84))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "######################################\n",
    "\n",
    "\n",
    "######################################\n",
    "#TODO:\n",
    "# Define your loss and your objective\n",
    "optimizer = 'rmsprop'\n",
    "loss = 'sparse_categorical_crossentropy'\n",
    "######################################\n",
    "\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Time\n",
    "Train the network. Be on the lookout for the validation loss and accuracy. Don't change any of the parameters here except for the batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 25s 505us/step - loss: 0.2446 - acc: 0.9265 - val_loss: 0.1320 - val_acc: 0.9635\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 25s 506us/step - loss: 0.1141 - acc: 0.9658 - val_loss: 0.0957 - val_acc: 0.9736\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 30s 599us/step - loss: 0.0896 - acc: 0.9729 - val_loss: 0.1079 - val_acc: 0.9685\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 26s 515us/step - loss: 0.0737 - acc: 0.9775 - val_loss: 0.1643 - val_acc: 0.9541\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 24s 487us/step - loss: 0.0659 - acc: 0.9798 - val_loss: 0.0935 - val_acc: 0.9747\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0584 - acc: 0.9812 - val_loss: 0.1204 - val_acc: 0.9669\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 0.0523 - acc: 0.9831 - val_loss: 0.1236 - val_acc: 0.9671\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0484 - acc: 0.9851 - val_loss: 0.1046 - val_acc: 0.9738\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 23s 461us/step - loss: 0.0449 - acc: 0.9855 - val_loss: 0.0995 - val_acc: 0.9764\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 23s 461us/step - loss: 0.0403 - acc: 0.9869 - val_loss: 0.1141 - val_acc: 0.9749\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ca9da517f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################################\n",
    "#TODO:\n",
    "# Define the batch size\n",
    "batch_size = 64\n",
    "######################################\n",
    "\n",
    "\n",
    "model.fit(train_X, train_Y, batch_size=batch_size, epochs=EPOCHS, validation_data=valid_set, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Time\n",
    "Now it's time to actually test the network. \n",
    "\n",
    "Get above **65%**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 185us/step\n",
      "\n",
      "Got 97.35% accuracy\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(test_X, test_Y, batch_size=batch_size, verbose=1)\n",
    "\n",
    "print('')\n",
    "print('Got %.2f%% accuracy' % (acc * 100.))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:caispp]",
   "language": "python",
   "name": "conda-env-caispp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
